{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eZOXEmjdEry"
      },
      "source": [
        "# <font color='red'>TME ROBOTIQUE ET APPRENTISSAGE</font>\n",
        "# <font color='red'>Evolution de structures</font>\n",
        "\n",
        "<font color=\"red\">Version étudiant 2022-2023</font>\n",
        "\n",
        "*mise à jour: 12/04/2023*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azdy5_zwdEr0"
      },
      "source": [
        "Ce notebook peut être exécuté dans [Google Colab](colab.research.google.com/)\n",
        "\n",
        "Pour faciliter la lisibilité du notebook, le code donné, à écrire ou à compléter est dans les cellules en annexe, à la fin du notebook. Les cellules de réponses ne doivent contenir que les quelques instructions permettant d'afficher les résultats (éventuellement des appels permettant de les générer) et les commentaires d'analyse associés.\n",
        "\n",
        "Vous devez déposer votre travail sur Moodle:\n",
        "* déposer votre notebook, avec le nom de fichier *obligatoirement* au format suivant: **RA_NOM1_NOM2.ipynb**\n",
        "* toutes les cellules exécutées\n",
        "* des graphes et un commentaire sur les résultats obtenus\n",
        "* affichage limité au nécessaire pour assurer la lisibilité du notebook (pas d'affichage de debug ni de centaines de graphes !)\n",
        "\n",
        "*Le sujet est à faire en binome.*\n",
        "\n",
        "# COMPLETEZ LES CHAMPS CI-DESSOUS AVEC NOM/PRENOM/CARTE_ETU:\n",
        "\n",
        "* Étudiant 1: **_Slimani_ _Nour_ _Ismahane_ _21221230_**\n",
        "* Étudiant 2: **_Buisson_ _Marc_ _28614429_**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7HpdGjbdEr2"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Ce TME est composé de deux parties indépendantes qui s'appuieront toutes deux sur le framework DEAP que vous avez utilisé lors des TME précédents.\n",
        "\n",
        "Dans la première partie, vous ferez de la regression symbolique avec de la programmation génétique.\n",
        "\n",
        "Dans la seconde partie, vous testerez l'expérience de Lehman et Stanley sur novelty search.\n",
        "\n",
        "Installation des dépendances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2874
        },
        "id": "2AFjn7nydEr3",
        "outputId": "f859c2dd-39c1-4b9a-84b2-6c418de02264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/135.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.23.5)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.4.1\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Collecting scoop\n",
            "  Downloading scoop-0.7.2.0.tar.gz (615 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: greenlet>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from scoop) (3.0.0)\n",
            "Requirement already satisfied: pyzmq>=13.1.0 in /usr/local/lib/python3.10/dist-packages (from scoop) (23.2.1)\n",
            "Building wheels for collected packages: scoop\n",
            "  Building wheel for scoop (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scoop: filename=scoop-0.7.2.0-py3-none-any.whl size=78112 sha256=94715251b986f927c5b9d5c04566abf111fecbc4705f3c85b74726243119e73c\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/c6/da/088e4bffcfbc33fa40644ca636267bc801c8fd9eef973483db\n",
            "Successfully built scoop\n",
            "Installing collected packages: scoop\n",
            "Successfully installed scoop-0.7.2.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libgvc6-plugins-gtk\n",
            "  librsvg2-common libxdot4\n",
            "Suggested packages:\n",
            "  gvfs\n",
            "The following NEW packages will be installed:\n",
            "  libgail-common libgail18 libgraphviz-dev libgtk2.0-0 libgtk2.0-bin libgtk2.0-common\n",
            "  libgvc6-plugins-gtk librsvg2-common libxdot4\n",
            "0 upgraded, 9 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 2,433 kB of archives.\n",
            "After this operation, 7,694 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2 [125 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2 [2,037 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgail18 amd64 2.24.33-2ubuntu2 [15.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgail-common amd64 2.24.33-2ubuntu2 [132 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libxdot4 amd64 2.42.2-6 [16.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libgvc6-plugins-gtk amd64 2.42.2-6 [22.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libgraphviz-dev amd64 2.42.2-6 [58.5 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2 [7,932 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Fetched 2,433 kB in 1s (4,280 kB/s)\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "(Reading database ... 120874 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libgtk2.0-common_2.24.33-2ubuntu2_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../1-libgtk2.0-0_2.24.33-2ubuntu2_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../2-libgail18_2.24.33-2ubuntu2_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../3-libgail-common_2.24.33-2ubuntu2_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package libxdot4:amd64.\n",
            "Preparing to unpack .../4-libxdot4_2.42.2-6_amd64.deb ...\n",
            "Unpacking libxdot4:amd64 (2.42.2-6) ...\n",
            "Selecting previously unselected package libgvc6-plugins-gtk.\n",
            "Preparing to unpack .../5-libgvc6-plugins-gtk_2.42.2-6_amd64.deb ...\n",
            "Unpacking libgvc6-plugins-gtk (2.42.2-6) ...\n",
            "Selecting previously unselected package libgraphviz-dev:amd64.\n",
            "Preparing to unpack .../6-libgraphviz-dev_2.42.2-6_amd64.deb ...\n",
            "Unpacking libgraphviz-dev:amd64 (2.42.2-6) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../7-libgtk2.0-bin_2.24.33-2ubuntu2_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../8-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libxdot4:amd64 (2.42.2-6) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2) ...\n",
            "Setting up libgvc6-plugins-gtk (2.42.2-6) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2) ...\n",
            "Setting up libgraphviz-dev:amd64 (2.42.2-6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.2) ...\n",
            "Collecting pygraphviz\n",
            "  Downloading pygraphviz-1.11.zip (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.8/120.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pygraphviz\n",
            "  Building wheel for pygraphviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygraphviz: filename=pygraphviz-1.11-cp310-cp310-linux_x86_64.whl size=175927 sha256=27f865832cc1faae3203d1c70f06860276f29db9dd39401b11dc4458d0f970a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ee/36/f47a0d35664fbe1a2b5a433ae33c6ad636b00bb231f68a9aaa\n",
            "Successfully built pygraphviz\n",
            "Installing collected packages: pygraphviz\n",
            "Successfully installed pygraphviz-1.11\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.2 [186 kB]\n",
            "Fetched 186 kB in 0s (733 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 121025 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.2) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.16.3\n",
            "Collecting plot\n",
            "  Downloading plot-0.6.5-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.1/135.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from plot) (3.7.1)\n",
            "Collecting typing (from plot)\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from plot) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from plot) (1.11.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from plot) (6.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->plot) (1.16.0)\n",
            "Building wheels for collected packages: typing\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26305 sha256=26bc5b46eb79937a97dcd073b9f37ffb5a6a0f8148083d3bbc8ca0676cd44ae3\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/d0/9e/1f26ebb66d9e1732e4098bc5a6c2d91f6c9a529838f0284890\n",
            "Successfully built typing\n",
            "Installing collected packages: typing, plot\n",
            "Successfully installed plot-0.6.5 typing-3.7.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install deap\n",
        "!pip install gym\n",
        "!pip install scoop\n",
        "!apt install libgraphviz-dev\n",
        "!pip install pygraphviz\n",
        "!apt install poppler-utils\n",
        "!pip install pdf2image\n",
        "!pip install plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL0lgpqudEr4"
      },
      "source": [
        "Sur les machines de TME (ou sur votre machine), vous pouvez également utiliser singularity, qui est un outil permettant de gérer des \"containers\" contenant tout l'environnement logiciel et les dépendances nécessaires, cf https://sylabs.io/guides/3.5/user-guide/index.html.\n",
        "\n",
        "L'image singularity est disponible sur moodle.\n",
        "\n",
        "Vous devez la copier en local sur votre machine (elle ne doit pas être dans un répertoire accessible par le réseau). Vous pouvez ensuite lancer un shell de la façon suivante:\n",
        "<pre>singularity shell TME_RA.sif </pre>\n",
        "Cela vous donnera accès à un shell dans lequel toutes les dépendances sont disponibles.\n",
        "\n",
        "Remarque: singularity attache par défaut votre répertoire home à l'image singularity. C'est très pratique, mais cela peut poser des difficultés en python si vous avez des bibliothèques installées en local. Vous pouvez utiliser l'option --no-home pour éviter ce type de problème. Pour accéder à vos fichiers, vous pouvez alors demander à monter un répertoire particulier dans votre image avec l'argument --bind TME_hors_singularity:/TME_dans_singularity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2utLU6gddEr5"
      },
      "source": [
        "## 1. Regression symbolique\n",
        "\n",
        "Vous allez utiliser la programmation génétique pour retrouver des équations à partir de données.\n",
        "Vous utiliserez pour cela les fonctions proposées par DEAP:\n",
        "https://deap.readthedocs.io/en/master/tutorials/advanced/gp.html et vous pourrez vous inspirez des exemples de programmation génétique donnés dans la documentation: https://deap.readthedocs.io/en/master/examples/gp_symbreg.html.\n",
        "\n",
        "\n",
        "**1.1-** Complétez le code qui vous a été fourni (annexe, question 1-3, `symbolic_regression.py`). En vous appuyant sur DEAP, vous implémenterez 3 stratégies:\n",
        "* une stratégie purement élitiste visant à minimiser l'erreur d'approximation uniquement,\n",
        "* la stratégie avec double tournoi, le premier tournoi choisissant les individus avec les erreurs les plus faibles et le second tournoi choisissant les individus avec le modèle le plus simple\n",
        "* une stratégie multi-objectif s'appuyant sur NSGA-2 avec l'erreur d'approximation comme premier objectif et la taille du modèle en deuxième objectif (les deux étant à minimiser)\n",
        "\n",
        "Vous testerez votre code sur une fonction simple (par exemple f(x,y)=x*y+cos(x)) avec le jeu de fonctions primitives suivant: +, -, *, / (protected_div), cos et sin. Vous pourrez ajouter une constante (1) et une constante éphémère (variable aléatoire uniforme entre -1 et 1).\n",
        "\n",
        "Vous génèrerez un ensemble de données d'entrainement et un ensemble de validation que vous utiliserez pour vérifier s'il y a eu surapprentissage. Vous pourrez générer, par exemple, 30 valeurs différentes de x et 30 valeurs différentes de y. Vous indiquerez dans votre réponse les opérateurs de mutation et de croisement que vous avez utilisés (remarque: si vous voulez combiner plusieurs opérateurs de mutation ou de croisement, il faut définir un nouvel opérateur qui gère cette combinaison).\n",
        "\n",
        "Vous regarderez les arbres générés et indiquerez le nombre de fois que la fonction a été retrouvée sur une dizaine d'expériences. Vous comparerez la taille des fonctions générées selon la variante de sélection utilisée.\n",
        "\n",
        "**Remarque1:** pour rappel, la programmation génétique utilise généralement de grandes populations. Il vous est recommandé d'utiliser des tailles de 400 minimum. En une centaine de générations, vous devriez pouvoir observer de premiers résultats.\n",
        "\n",
        "**Remarque2:** pour limiter l'impact du \"bloat\", il vous est recommandé de mettre une taille maximale à l'arbre généré par les opérateurs de mutation et de croisement. Vous pourrez utiliser gp.staticLimit. Sans cela, certaines expériences risquent de prendre un temps et une mémoire considérables.\n",
        "\n",
        "Complétez le squelette de code donné en annexe. L'exécution de la cellule sauvegardera son contenu que vous pourrez ensuite appeler dans un terminal ou directement depuis le notebook en transmettant les arguments décrivant la variante que vous souhaitez tester (tournoi, nsga2, ...).\n",
        "\n",
        "Vous pourrez afficher des arbres dans votre notebook en vous inspirant du code fourni ou en affichant directement le PDF dans le notebook avec les commandes suivantes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "4u4G_6QcdEr6",
        "outputId": "64cc5b98-68f7-4ff7-da63-5592e0739822"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "PDFPageCountError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdf2image/pdf2image.py\u001b[0m in \u001b[0;36mpdfinfo_from_path\u001b[0;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"Pages\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mPDFPageCountError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-df0c564805b5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpdf2image\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_from_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# first page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdf2image/pdf2image.py\u001b[0m in \u001b[0;36mconvert_from_path\u001b[0;34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, ownerpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mpoppler_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoppler_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     page_count = pdfinfo_from_path(\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mpdf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserpw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mownerpw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoppler_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoppler_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     )[\"Pages\"]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdf2image/pdf2image.py\u001b[0m in \u001b[0;36mpdfinfo_from_path\u001b[0;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout)\u001b[0m\n\u001b[1;32m    596\u001b[0m         )\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         raise PDFPageCountError(\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;34mf\"Unable to get page count.\\n{err.decode('utf8', 'ignore')}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         )\n",
            "\u001b[0;31mPDFPageCountError\u001b[0m: Unable to get page count.\nI/O Error: Couldn't open file 'res_dir/hof_tree_genX.pdf': No such file or directory.\n"
          ]
        }
      ],
      "source": [
        "filepath=\"res_dir/hof_tree_genX.pdf\"\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "images = convert_from_path(filepath)\n",
        "images[0]  # first page\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rbcNYlK3dEr7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "71457027-c0db-4b8d-92d3-055cc7703ff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/symbolic_regression.py': [Errno 2] No such file or directory\n",
            "CPU times: user 4.97 ms, sys: 0 ns, total: 4.97 ms\n",
            "Wall time: 107 ms\n"
          ]
        }
      ],
      "source": [
        "#<ANSWER>\n",
        "%%time\n",
        "!python3 symbolic_regression.py\n",
        "\n",
        "#</ANSWER>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tFz--01dEr7"
      },
      "source": [
        "**1.2-** Ajoutez du bruit à vos fonctions et observez le résultat obtenu (mettez des valeurs qui sont faibles devant les données, par exemple 0.0001)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nGPmZ-DGdEr8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "13062eb4-bcde-4f5a-b8aa-67342fb86de8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/symbolic_regression.py': [Errno 2] No such file or directory\n",
            "CPU times: user 6.32 ms, sys: 0 ns, total: 6.32 ms\n",
            "Wall time: 106 ms\n"
          ]
        }
      ],
      "source": [
        "#<ANSWER>\n",
        "%%time\n",
        "!python3 symbolic_regression.py\n",
        "#</ANSWER>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuCXaQL-dEr9"
      },
      "source": [
        "## 2. Fitness & Nouveauté\n",
        "\n",
        "L'environnement `FastsimSimpleNavigation-v0` de gym_fastsim permet de lancer des expériences de navigation avec un robot à roues naviguant dans un labyrinthe. Vous allez dans cette partie reproduire les expériences de Lehman et Stanley sur la recherche de nouveauté. Vous allez faire différentes variantes de cette expérience, certaines étant en mono- d'autres étant en multi-objectif. Pour simplifier, dans tous les cas, vous utiliserez NSGA-2, qui est équivalent à une stratégie élitiste en mono-objectif.\n",
        "\n",
        "Pour installer l'environnement dans collab ou jupyter, utiliser les commandes suivantes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "n0czGaF9dEr9",
        "outputId": "7555e30f-7ff9-4733-f0bf-9a9696fa9fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'libfastsim'...\n",
            "remote: Enumerating objects: 274, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 274 (delta 5), reused 10 (delta 2), pack-reused 252\u001b[K\n",
            "Receiving objects: 100% (274/274), 272.83 KiB | 3.00 MiB/s, done.\n",
            "Resolving deltas: 100% (161/161), done.\n",
            "\u001b[32m\u001b[0mSetting top to                           :\u001b[0m \u001b[0m\u001b[32m\u001b[32m/content/libfastsim\u001b[0m \u001b[0m\n",
            "\u001b[32m\u001b[0mSetting out to                           :\u001b[0m \u001b[0m\u001b[32m\u001b[32m/content/libfastsim/build\u001b[0m \u001b[0m\n",
            "configuring b-optimize\n",
            "\u001b[32m\u001b[0mChecking for 'g++' (C++ compiler)        :\u001b[0m \u001b[0m\u001b[32m\u001b[32m/usr/bin/g++\u001b[0m \u001b[0m\n",
            "\u001b[32m\u001b[0mChecking for 'gcc' (C compiler)          :\u001b[0m \u001b[0m\u001b[32m\u001b[32m/usr/bin/gcc\u001b[0m \u001b[0m\n",
            "\u001b[32m\u001b[0mChecking for SDL (1.2 - sdl-config)      :\u001b[0m \u001b[0m\u001b[32m\u001b[01;31msdl-config not found\u001b[0m \u001b[0m\n",
            "['-Wall', '-O3', '-msse2', '-fPIC']\n",
            "\u001b[32m'configure' finished successfully (0.255s)\u001b[0m\n",
            "\u001b[32mWaf: Entering directory `/content/libfastsim/build'\u001b[0m\n",
            "[ 1/11] Compiling \u001b[32msrc/linear_camera.cpp\u001b[0m\n",
            "[ 2/11] Compiling \u001b[32msrc/map.cpp\u001b[0m\n",
            "[ 3/11] Compiling \u001b[32msrc/display.cpp\u001b[0m\n",
            "[ 4/11] Compiling \u001b[32msrc/robot.cpp\u001b[0m\n",
            "[ 5/11] Compiling \u001b[32msrc/light_sensor.cpp\u001b[0m\n",
            "[ 6/11] Compiling \u001b[32msrc/radar.cpp\u001b[0m\n",
            "[ 7/11] Compiling \u001b[32msrc/settings.cpp\u001b[0m\n",
            "[ 8/11] Compiling \u001b[32msrc/laser.cpp\u001b[0m\n",
            "[ 9/11] Compiling \u001b[32msrc/main.cpp\u001b[0m\n",
            "[10/11] Linking \u001b[33mbuild/src/libfastsim.a\u001b[0m\n",
            "[11/11] Linking \u001b[33mbuild/src/test_fastsim\u001b[0m\n",
            "\u001b[32mWaf: Leaving directory `/content/libfastsim/build'\u001b[0m\n",
            "\u001b[32m'build' finished successfully (14.905s)\u001b[0m\n",
            "\u001b[32mWaf: Entering directory `/content/libfastsim/build'\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/bin/test_fastsim\u001b[0m (from build/src/test_fastsim)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/include/libfastsim/illuminated_switch.hpp\u001b[0m (from src/illuminated_switch.hpp)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/include/libfastsim/settings.hpp\u001b[0m (from src/settings.hpp)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/include/libfastsim/misc.hpp\u001b[0m (from src/misc.hpp)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/include/libfastsim/linear_camera.hpp\u001b[0m (from src/linear_camera.hpp)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/include/libfastsim/map.hpp\u001b[0m (from src/map.hpp)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/include/libfastsim/goal.hpp\u001b[0m (from src/goal.hpp)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/include/libfastsim/laser_scanner.hpp\u001b[0m (from src/laser_scanner.hpp)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/include/libfastsim/robot.hpp\u001b[0m (from src/robot.hpp)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/include/libfastsim/posture.hpp\u001b[0m (from src/posture.hpp)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/include/libfastsim/display.hpp\u001b[0m (from src/display.hpp)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/include/libfastsim/laser.hpp\u001b[0m (from src/laser.hpp)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/include/libfastsim/fastsim.hpp\u001b[0m (from src/fastsim.hpp)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/include/libfastsim/radar.hpp\u001b[0m (from src/radar.hpp)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/include/libfastsim/light_sensor.hpp\u001b[0m (from src/light_sensor.hpp)\u001b[0m\n",
            "\u001b[32m\u001b[0m+ install \u001b[01;34m/usr/local/lib/libfastsim.a\u001b[0m (from build/src/libfastsim.a)\u001b[0m\n",
            "\u001b[32mWaf: Leaving directory `/content/libfastsim/build'\u001b[0m\n",
            "\u001b[32m'install' finished successfully (0.020s)\u001b[0m\n",
            "Cloning into 'pyfastsim'...\n",
            "remote: Enumerating objects: 123, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 123 (delta 0), reused 3 (delta 0), pack-reused 117\u001b[K\n",
            "Receiving objects: 100% (123/123), 31.67 KiB | 3.96 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n",
            "Processing /content/pyfastsim\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from pyfastsim==0.1.0)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyfastsim\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pyfastsim (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyfastsim\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for pyfastsim\n",
            "Failed to build pyfastsim\n",
            "\u001b[31mERROR: Could not build wheels for pyfastsim, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mCloning into 'fastsim_gym'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 129 (delta 17), reused 37 (delta 16), pack-reused 87\u001b[K\n",
            "Receiving objects: 100% (129/129), 21.06 KiB | 7.02 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n",
            "Processing /content/fastsim_gym\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gym>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from gym-fastsim==0.0.6) (0.25.2)\n",
            "INFO: pip is looking at multiple versions of gym-fastsim to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyfastsim (from gym-fastsim) (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pyfastsim\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sferes2/libfastsim\n",
        "!cd libfastsim && ./waf configure build install\n",
        "!git clone https://github.com/alexendy/pyfastsim\n",
        "!cd pyfastsim && pip install .\n",
        "!git clone https://github.com/alexendy/fastsim_gym\n",
        "!cd fastsim_gym && pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxWY2fwrdEr-"
      },
      "source": [
        "Remarque: pour une installation sur les machines de TME, vous n'aurez pas les droits pour installer fastsim dans les répertoires système. Dans ce cas, vous pouvez ajouter l'installer dans votre répertoire en ajoutant un argument 'prefix' au waf configure et ajouter le répertoire des libs ainsi créé à la variable d'environnement LIBRARY_PATH et le répertoire des fichiers headers à la variable d'environnement CPATH. Une fois cela fait, vous pouvez faire appel au pip install de pyfastsim puis de fastsim_gym."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g_XIMELdEr_"
      },
      "source": [
        "**2.1-**  Lancer une première expérience dans laquelle le robot doit atteindre la sortie du labyrinthe. Vous pourrez essayer avec la reward de l'expérience, qui est une reward binaire (sortie atteinte ou non) et avec une fitness plus continue dans laquelle la récompense est la distance à la sortie (à minimiser donc). Pour observer le comportement de la recherche effectuée, vous pourrez écrire la position du robot à la fin de l'évaluation et ensuite tracer ces positions avec les fonctions fournies dans `maze_plot.py` (vous pouvez aussi tracer les trajectoires, mais comme il y a 2000 positions par évaluation, dans ce cas, vous pourrez n'écrire qu'une position sur 100, par exemple).\n",
        "\n",
        "Quelles parties de l'espace ont été explorées dans les deux cas ? Est-ce que la sortie est atteinte (vous vous limiterez à 200 générations) ? Si oui, au bout de combien de générations ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "c7i0OyWzdEr_",
        "outputId": "f4be2fb9-1b02-443f-dfa9-557689d65afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/gym_fastsim_maze.py': [Errno 2] No such file or directory\n",
            "CPU times: user 7.63 ms, sys: 59 µs, total: 7.69 ms\n",
            "Wall time: 138 ms\n"
          ]
        }
      ],
      "source": [
        "#<ANSWER>\n",
        "%%time\n",
        "!python3 gym_fastsim_maze.py\n",
        "#</ANSWER>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhLGqxjRdEr_"
      },
      "source": [
        "**2.2-** Lancer la même expérience, mais avec un critère de nouveauté. Vous pourrez pour cela partir du code fourni pour le calcul de nouveauté (`novelty_search.py`) et le compléter.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HFGnRXpbdEsA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "93c21b5d-a77b-44d7-8a97-9c097a36a709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/gym_fastsim_maze.py': [Errno 2] No such file or directory\n",
            "CPU times: user 7.65 ms, sys: 3 µs, total: 7.66 ms\n",
            "Wall time: 318 ms\n"
          ]
        }
      ],
      "source": [
        "#<ANSWER>\n",
        "%%time\n",
        "!python3 gym_fastsim_maze.py --variant \"NS\"\n",
        "#</ANSWER>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kOlC0JOdEsA"
      },
      "source": [
        "**2.3-** Utiliser en même temps la fitness et le critère de nouveauté avec NSGA-2. Mesurez le temps moyen pour atteindre la sortie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLFDE3GmdEsB"
      },
      "outputs": [],
      "source": [
        "#<ANSWER>\n",
        "\n",
        "#</ANSWER>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBvEfcjMdEsB"
      },
      "source": [
        "## Annexes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y3BTf9XLdEsC"
      },
      "outputs": [],
      "source": [
        "from IPython.core.magic import register_cell_magic\n",
        "@register_cell_magic\n",
        "def run_and_save(line, cell):\n",
        "    print(\"Run and save python code block to file: \"+line)\n",
        "    with open(line, 'wt') as fd:\n",
        "        fd.write(cell)\n",
        "    code = compile(cell, line, 'exec')\n",
        "    exec(code, globals())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYPEi0D5dEsC"
      },
      "source": [
        "### Question 1.1 à 1.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "843pEvfSio_G",
        "outputId": "65bca584-a2fa-464c-fca5-c0ce08c56335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing symbolic_regression.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile symbolic_regression.py\n",
        "\n",
        "# cellule à compléter au niveau des balises <ANSWER></ANSWER>\n",
        "\n",
        "from deap import creator, gp, base, tools, algorithms\n",
        "import operator\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import argparse\n",
        "import pickle\n",
        "import datetime\n",
        "import sys\n",
        "import os\n",
        "\n",
        "\n",
        "def protectedDiv(left, right):\n",
        "    try:\n",
        "        return left / right\n",
        "    except ZeroDivisionError:\n",
        "        return 1\n",
        "\n",
        "def ru():\n",
        "    return random.uniform(-1,1)\n",
        "\n",
        "\n",
        "\n",
        "def evalSymbReg(individual, input, output, nb_obj=1):\n",
        "    # Transform the tree expression in a callable function\n",
        "    func = toolbox.compile(expr=individual)\n",
        "    sqerrors=[]\n",
        "    for i in range(len(input)):\n",
        "        sqerrors.append((func(*input[i])-output[i])**2)\n",
        "    if (nb_obj==1):\n",
        "        return math.fsum(sqerrors) / len(sqerrors),\n",
        "    else:\n",
        "        return math.fsum(sqerrors) / len(sqerrors), len(individual)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if (__name__ == \"__main__\"):\n",
        "\n",
        "    random.seed()\n",
        "\n",
        "\n",
        "    parser = argparse.ArgumentParser(description='Launch symbolic regression run.')\n",
        "\n",
        "    parser.add_argument('--nb_gen', type=int, default=200,\n",
        "                        help='number of generations')\n",
        "    parser.add_argument('--mu', type=int, default=400,\n",
        "                        help='population size')\n",
        "    parser.add_argument('--lambda_', type=int, default=400,\n",
        "                        help='number of individuals to generate')\n",
        "    parser.add_argument('--res_dir', type=str, default=\"res\",\n",
        "                        help='basename of the directory in which to put the results')\n",
        "    parser.add_argument('--selection', type=str, default=\"elitist\", choices=['elitist', 'double_tournament', 'nsga2'],\n",
        "                        help='selection scheme')\n",
        "    parser.add_argument('--problem', type=str, default=\"f1\", choices=['f1', 'f2'],\n",
        "                        help='function to fit')\n",
        "\n",
        "    # for question 1.2\n",
        "    parser.add_argument('--noise', type=float, default=\"0.0001\",\n",
        "                        help='noise added to the model to fit (gaussian, mean=0, sigma=noise)')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    print(\"Number of generations: \"+str(args.nb_gen))\n",
        "    ngen=args.nb_gen\n",
        "    print(\"Population size: \"+str(args.mu))\n",
        "    mu=args.mu\n",
        "    print(\"Number of offspring to generate: \"+str(args.lambda_))\n",
        "    lambda_=args.lambda_\n",
        "    print(\"Selection scheme: \"+str(args.selection))\n",
        "    sel=args.selection\n",
        "    if (sel==\"nsga2\"):\n",
        "        nb_obj=2\n",
        "    else:\n",
        "        nb_obj=1\n",
        "    print(\"Basename of the results dir: \"+str(args.res_dir))\n",
        "    name=args.res_dir\n",
        "\n",
        "    if (nb_obj==1):\n",
        "        creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
        "    elif (nb_obj==2):\n",
        "        creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,-1.0))\n",
        "\n",
        "    creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin)\n",
        "\n",
        "    noise=args.noise\n",
        "    problem=args.problem\n",
        "\n",
        "    d=datetime.datetime.today()\n",
        "    if(name!=\"\"):\n",
        "        sep=\"_\"\n",
        "    else:\n",
        "        sep=\"\"\n",
        "    run_name=name+\"_\"+sel+\"_\"+d.strftime(name+sep+\"%Y_%m_%d-%H-%M-%S\")\n",
        "    try:\n",
        "        os.makedirs(run_name)\n",
        "    except OSError:\n",
        "        pass\n",
        "\n",
        "    print(\"Putting the results in : \"+run_name)\n",
        "\n",
        "    stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "    stats_size = tools.Statistics(len)\n",
        "    stats_height = tools.Statistics(lambda ind: ind.height)\n",
        "    mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size, height=stats_height)\n",
        "    mstats.register(\"avg\", np.mean)\n",
        "    mstats.register(\"std\", np.std)\n",
        "    mstats.register(\"min\", np.min)\n",
        "    mstats.register(\"max\", np.max)\n",
        "\n",
        "\n",
        "    if (problem==\"f1\"):\n",
        "        nb_dim=2\n",
        "        input_training=[]\n",
        "        output_training=[]\n",
        "        input_testing=[]\n",
        "        output_testing=[]\n",
        "        name_vars={\"ARG0\": \"x1\", \"ARG1\": \"x2\"}\n",
        "\n",
        "        # Complétez pour générer l'ensemble d'entrainement et de validation avec une fonction choisie à 2 dimensions\n",
        "        #<ANSWER>\n",
        "        for i in range(30):\n",
        "            x, y=(random.uniform(-100., 100.), random.uniform(-100., 100.))\n",
        "            input_training.append((x,y))\n",
        "            output_training.append(x*y+math.cos(x))\n",
        "            x, y=(random.uniform(-100., 100.), random.uniform(-100., 100.))\n",
        "            input_testing.append((x,y))\n",
        "            output_testing.append(x*y+math.cos(x))\n",
        "        #</ANSWER>\n",
        "        print(input_training)\n",
        "        print(output_training)\n",
        "        print(input_testing)\n",
        "        print(output_testing)\n",
        "    # en OPTION: vous pouvez faire des tests sur d'autres fonctions\n",
        "    #elif (problem==\"f2\"):\n",
        "        #<ANSWER>\n",
        "\n",
        "        #</ANSWER>\n",
        "\n",
        "    pset = gp.PrimitiveSet(\"MAIN\", nb_dim)\n",
        "\n",
        "    # Complétez pour constituer l'ensemble de primitives qui pourront être utilisées\n",
        "    #<ANSWER>\n",
        "    pset.addPrimitive(operator.add, 2)\n",
        "    pset.addPrimitive(operator.sub, 2)\n",
        "    pset.addPrimitive(operator.mul, 2)\n",
        "    pset.addPrimitive(protectedDiv, 2)\n",
        "    pset.addPrimitive(math.cos, 1)\n",
        "    pset.addPrimitive(math.sin, 1)\n",
        "    #</ANSWER>\n",
        "\n",
        "    pset.addTerminal(1)\n",
        "    pset.addEphemeralConstant(\"cst\", ru )\n",
        "    pset.renameArguments(**name_vars)\n",
        "\n",
        "    cxpb=0.5\n",
        "    mutpb=0.1\n",
        "\n",
        "\n",
        "    toolbox = base.Toolbox()\n",
        "\n",
        "    # En vous inspirant des exemples de programmation génétique dans DEAP,\n",
        "    # enregistrez les différents opérateurs que vous utiliserez dans la suite.\n",
        "    # Vous choisirez l'opérateur de sélection en fonction de la variable sel\n",
        "    # (voir valeurs possibles dans le parser d'arguments)\n",
        "    #<ANSWER>\n",
        "    toolbox.register(\"expr\", gp.genFull, pset=pset, min_=1, max_=2)\n",
        "    toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
        "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "    toolbox.register(\"compile\", gp.compile, pset=pset)\n",
        "\n",
        "    toolbox.register(\"evaluate\", evalSymbReg, input=input_training, output=output_training)\n",
        "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "    toolbox.register(\"mate\", gp.cxOnePoint)\n",
        "    toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
        "    toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
        "\n",
        "    toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))\n",
        "    toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))\n",
        "    #</ANSWER>\n",
        "\n",
        "    pop = toolbox.population(n=400)\n",
        "\n",
        "    if (nb_obj==1):\n",
        "        print(\"Hall-of-fame: best solution\")\n",
        "        hof = tools.HallOfFame(1)\n",
        "    else:\n",
        "        print(\"Hall-of-fame: Pareto front\")\n",
        "        hof=tools.ParetoFront()\n",
        "\n",
        "    # Pour simplifier, plutôt que d'écrire la boucle, vous pourrez utiliser un algorithme tout intégré,\n",
        "    # par exemple eaMuPlusLambda (cf https://deap.readthedocs.io/en/master/api/algo.html).\n",
        "    # Cela ne permettra pas de générer un NSGA-II complet, mais cela vous permettra de faire de premiers tests.\n",
        "    # En option, si vous avez le temps, vous pourrez tester un NSGA-II complet pour voir si cela change les résultats.\n",
        "    #<ANSWER>\n",
        "    pop, log = algorithms.eaMuPlusLambda(pop, toolbox, mu, lambda_, cxpb, mutpb, ngen, stats=mstats, halloffame=hof)\n",
        "    #</ANSWER>\n",
        "\n",
        "    # Affichage des résultats. Tout est dans le répertoire run_name\n",
        "    avg,dmin,dmax=log.chapters['fitness'].select(\"avg\", \"min\", \"max\")\n",
        "    gen=log.select(\"gen\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.yscale(\"log\")\n",
        "    plt.plot(gen[1:],dmin[1:])\n",
        "    plt.title(\"Minimum error\")\n",
        "    plt.savefig(run_name+\"/min_error_gen%d.pdf\"%(ngen))\n",
        "\n",
        "    plt.figure()\n",
        "    plt.yscale(\"log\")\n",
        "    plt.fill_between(gen[1:], dmin[1:], dmax[1:], alpha=0.25, linewidth=0)\n",
        "    plt.plot(gen[1:],avg[1:])\n",
        "    plt.title(\"Average error\")\n",
        "    plt.savefig(run_name+\"/avg_error_gen%d.pdf\"%(ngen))\n",
        "\n",
        "    avg,dmin,dmax=log.chapters['size'].select(\"avg\", \"min\", \"max\")\n",
        "    gen=log.select(\"gen\")\n",
        "    plt.figure()\n",
        "    plt.yscale(\"log\")\n",
        "    plt.fill_between(gen[1:], dmin[1:], dmax[1:], alpha=0.25, linewidth=0)\n",
        "    plt.plot(gen[1:],avg[1:])\n",
        "    plt.title(\"Average size\")\n",
        "    plt.savefig(run_name+\"/avg_size_gen%d.pdf\"%(ngen))\n",
        "\n",
        "    avg,dmin,dmax=log.chapters['height'].select(\"avg\", \"min\", \"max\")\n",
        "    gen=log.select(\"gen\")\n",
        "    plt.figure()\n",
        "    plt.yscale(\"log\")\n",
        "    plt.fill_between(gen[1:], dmin[1:], dmax[1:], alpha=0.25, linewidth=0)\n",
        "    plt.plot(gen[1:],avg[1:])\n",
        "    plt.title(\"Average height\")\n",
        "    plt.savefig(run_name+\"/avg_height_gen%d.pdf\"%(ngen))\n",
        "\n",
        "    with open(run_name+\"/pset_gen%d.npz\"%(ngen), 'wb') as f:\n",
        "        pickle.dump(pset, f)\n",
        "\n",
        "\n",
        "    for i,ind in enumerate(hof):\n",
        "        print(\"=========\")\n",
        "        print(\"HOF %d, len=%d\"%(i,len(ind)))\n",
        "        print(\"Error on the training dataset: %f\"%(evalSymbReg(ind, input_training, output_training, nb_obj=1)))\n",
        "        print(\"Error on the testing dataset: %f\"%(evalSymbReg(ind, input_testing, output_testing, nb_obj=1)))\n",
        "        with open(run_name+\"/hof%d_gen%d.npz\"%(i, ngen), 'wb') as f:\n",
        "            pickle.dump(ind, f)\n",
        "\n",
        "        nodes, edges, labels = gp.graph(ind)\n",
        "\n",
        "        ### Graphviz Section ###\n",
        "        import pygraphviz as pgv\n",
        "\n",
        "        plt.figure()\n",
        "\n",
        "        g = pgv.AGraph()\n",
        "        g.add_nodes_from(nodes)\n",
        "        g.add_edges_from(edges)\n",
        "        g.layout(prog=\"dot\")\n",
        "\n",
        "        for ni in nodes:\n",
        "            n = g.get_node(ni)\n",
        "            n.attr[\"label\"] = labels[ni]\n",
        "\n",
        "\n",
        "        g.draw(run_name+\"/hof%d_tree_gen%d.pdf\"%(i,ngen))\n",
        "\n",
        "    print(\"Results saved in \"+run_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6-CY9WldEsE"
      },
      "source": [
        "## Code de la question 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QprDwwcTdEsF",
        "outputId": "75f8b446-17e1-4de5-c341-832d6e1611fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run and save python code block to file: maze_plot.py\n"
          ]
        }
      ],
      "source": [
        "%%run_and_save maze_plot.py\n",
        "#!/usr/bin/python -w\n",
        "\n",
        "# NE PAS MODIFIER LE CONTENU DE CETTE CELLULE\n",
        "# Cette cellule contient le code de fonctions permettant de tracer les points atteints\n",
        "# par les politiques de navigation générées.\n",
        "# Ce code n'a pas à être modifié ni complété, il suffit d'exécuter la cellule telle quelle.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_points(points, bg=\"maze_hard.pbm\", title=None):\n",
        "    x,y = zip(*points)\n",
        "    fig1, ax1 = plt.subplots()\n",
        "    ax1.set_xlim(0,600)\n",
        "    ax1.set_ylim(600,0) # Decreasing\n",
        "    ax1.set_aspect('equal')\n",
        "    if(bg):\n",
        "        img = plt.imread(bg)\n",
        "        ax1.imshow(img, extent=[0, 600, 600, 0])\n",
        "    if(title):\n",
        "        ax1.set_title(title)\n",
        "    ax1.scatter(x, y, s=2)\n",
        "    plt.show()\n",
        "\n",
        "def plot_points_lists(lpoints, bg=\"maze_hard.pbm\", title=None):\n",
        "    fig1, ax1 = plt.subplots()\n",
        "    ax1.set_xlim(0,600)\n",
        "    ax1.set_ylim(600,0) # Decreasing\n",
        "    ax1.set_aspect('equal')\n",
        "    if(bg):\n",
        "        img = plt.imread(bg)\n",
        "        ax1.imshow(img, extent=[0, 600, 600, 0])\n",
        "    if(title):\n",
        "        ax1.set_title(title)\n",
        "    for points in lpoints:\n",
        "        x,y = zip(*points)\n",
        "        ax1.scatter(x, y, s=2)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_points_file(filename, bg=\"maze_hard.pbm\", title=None):\n",
        "    try:\n",
        "        with open(filename) as f:\n",
        "            points=[]\n",
        "            for l in f.readlines():\n",
        "                pos=list(map(float, l.split(\" \")))\n",
        "                points.append(pos)\n",
        "            f.close()\n",
        "            plot_points(points, bg, title)\n",
        "    except IOError:\n",
        "        print(\"Could not read file: \"+f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FEHuhy_kdEsG",
        "outputId": "245546b5-7975-4564-e488-8e98435da878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run and save python code block to file: nn.py\n"
          ]
        }
      ],
      "source": [
        "%%run_and_save nn.py\n",
        "# NE PAS MODIFIER LE CONTENU DE CETTE CELLULE\n",
        "# Cette cellule contient le code de gestion d'une politique au travers d'un réseau de neurones de structure fixe.\n",
        "# Ce code n'a pas à être modifié ni complété, il suffit d'exécuter la cellule telle quelle.\n",
        "\n",
        "# coding: utf-8\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "## Suppress TF info messages\n",
        "\n",
        "import os\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1./(1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "\n",
        "def gen_simplemlp(n_in, n_out, n_hidden_layers=2, n_neurons_per_hidden=5):\n",
        "    n_neurons = [n_neurons_per_hidden]*n_hidden_layers if np.isscalar(n_neurons_per_hidden) else n_neurons_per_hidden\n",
        "    i = Input(shape=(n_in,))\n",
        "    x = i\n",
        "    for n in n_neurons:\n",
        "        x = Dense(n, activation='sigmoid')(x)\n",
        "    o = Dense(n_out, activation='tanh')(x)\n",
        "    m = Model(inputs=i, outputs=o)\n",
        "    return m\n",
        "\n",
        "\n",
        "class SimpleNeuralControllerNumpy():\n",
        "    def __init__(self, n_in, n_out, n_hidden_layers=2, n_neurons_per_hidden=5, params=None):\n",
        "        self.dim_in = n_in\n",
        "        self.dim_out = n_out\n",
        "        # if params is provided, we look for the number of hidden layers and neuron per layer into that parameter (a dicttionary)\n",
        "        if (not params==None):\n",
        "            if (\"n_hidden_layers\" in params.keys()):\n",
        "                n_hidden_layers=params[\"n_hidden_layers\"]\n",
        "            if (\"n_neurons_per_hidden\" in params.keys()):\n",
        "                n_neurons_per_hidden=params[\"n_neurons_per_hidden\"]\n",
        "        self.n_per_hidden = n_neurons_per_hidden\n",
        "        self.n_hidden_layers = n_hidden_layers\n",
        "        self.weights = None\n",
        "        self.n_weights = None\n",
        "        self.init_random_params()\n",
        "        self.out = np.zeros(n_out)\n",
        "        #print(\"Creating a simple mlp with %d inputs, %d outputs, %d hidden layers and %d neurons per layer\"%(n_in, n_out,n_hidden_layers, n_neurons_per_hidden))\n",
        "\n",
        "\n",
        "    def init_random_params(self):\n",
        "        if(self.n_hidden_layers > 0):\n",
        "            self.weights = [np.random.random((self.dim_in,self.n_per_hidden))] # In -> first hidden\n",
        "            self.bias = [np.random.random(self.n_per_hidden)] # In -> first hidden\n",
        "            for i in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
        "                self.weights.append(np.random.random((self.n_per_hidden,self.n_per_hidden)))\n",
        "                self.bias.append(np.random.random(self.n_per_hidden))\n",
        "            self.weights.append(np.random.random((self.n_per_hidden,self.dim_out))) # -> last hidden -> out\n",
        "            self.bias.append(np.random.random(self.dim_out))\n",
        "        else:\n",
        "            self.weights = [np.random.random((self.dim_in,self.dim_out))] # Single-layer perceptron\n",
        "            self.bias = [np.random.random(self.dim_out)]\n",
        "        self.n_weights = np.sum([np.product(w.shape) for w in self.weights]) + np.sum([np.product(b.shape) for b in self.bias])\n",
        "\n",
        "    def get_parameters(self):\n",
        "        \"\"\"\n",
        "        Returns all network parameters as a single array\n",
        "        \"\"\"\n",
        "        flat_weights = np.hstack([arr.flatten() for arr in (self.weights+self.bias)])\n",
        "        return flat_weights\n",
        "\n",
        "    def set_parameters(self, flat_parameters):\n",
        "        \"\"\"\n",
        "        Set all network parameters from a single array\n",
        "        \"\"\"\n",
        "        i = 0 # index\n",
        "        to_set = []\n",
        "        self.weights = list()\n",
        "        self.bias = list()\n",
        "        if(self.n_hidden_layers > 0):\n",
        "            # In -> first hidden\n",
        "            w0 = np.array(flat_parameters[i:(i+self.dim_in*self.n_per_hidden)])\n",
        "            self.weights.append(w0.reshape(self.dim_in,self.n_per_hidden))\n",
        "            i += self.dim_in*self.n_per_hidden\n",
        "            for l in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
        "                w = np.array(flat_parameters[i:(i+self.n_per_hidden*self.n_per_hidden)])\n",
        "                self.weights.append(w.reshape((self.n_per_hidden,self.n_per_hidden)))\n",
        "                i += self.n_per_hidden*self.n_per_hidden\n",
        "            # -> last hidden -> out\n",
        "            wN = np.array(flat_parameters[i:(i+self.n_per_hidden*self.dim_out)])\n",
        "            self.weights.append(wN.reshape((self.n_per_hidden,self.dim_out)))\n",
        "            i += self.n_per_hidden*self.dim_out\n",
        "            # Samefor bias now\n",
        "            # In -> first hidden\n",
        "            b0 = np.array(flat_parameters[i:(i+self.n_per_hidden)])\n",
        "            self.bias.append(b0)\n",
        "            i += self.n_per_hidden\n",
        "            for l in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
        "                b = np.array(flat_parameters[i:(i+self.n_per_hidden)])\n",
        "                self.bias.append(b)\n",
        "                i += self.n_per_hidden\n",
        "            # -> last hidden -> out\n",
        "            bN = np.array(flat_parameters[i:(i+self.dim_out)])\n",
        "            self.bias.append(bN)\n",
        "            i += self.dim_out\n",
        "        else:\n",
        "            n_w = self.dim_in*self.dim_out\n",
        "            w = np.array(flat_parameters[:n_w])\n",
        "            self.weights = [w.reshape((self.dim_in,self.dim_out))]\n",
        "            self.bias = [np.array(flat_parameters[n_w:])]\n",
        "        self.n_weights = np.sum([np.product(w.shape) for w in self.weights]) + np.sum([np.product(b.shape) for b in self.bias])\n",
        "\n",
        "    def predict(self,x):\n",
        "        \"\"\"\n",
        "        Propagage\n",
        "        \"\"\"\n",
        "        if(self.n_hidden_layers > 0):\n",
        "            #Input\n",
        "            a = np.matmul(x,self.weights[0]) + self.bias[0]\n",
        "            y = sigmoid(a)\n",
        "            # hidden -> hidden\n",
        "            for i in range(1,self.n_hidden_layers-1):\n",
        "                a = np.matmul(y, self.weights[i]) + self.bias[i]\n",
        "                y = sigmoid(a)\n",
        "            # Out\n",
        "            a = np.matmul(y, self.weights[-1]) + self.bias[-1]\n",
        "            out = tanh(a)\n",
        "            return out\n",
        "        else: # Simple monolayer perceptron\n",
        "            return tanh(np.matmul(x,self.weights[0]) + self.bias[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz21mdO0dEsG"
      },
      "source": [
        "### Question 2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BWLwrUgGdEsG",
        "outputId": "fb400a31-cafc-47a9-c011-2da22adc88c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run and save python code block to file: novelty_search.py\n"
          ]
        }
      ],
      "source": [
        "%%run_and_save novelty_search.py\n",
        "\n",
        "# Cette cellule contient le code permettant de gérer novelty search.\n",
        "# Complétez les trous dans les balises <ANSWER></ANSWER>\n",
        "\n",
        "from scipy.spatial import KDTree\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class NovArchive:\n",
        "    \"\"\"Archive used to compute novelty scores.\"\"\"\n",
        "    def __init__(self, lbd, k=15):\n",
        "        self.all_bd=lbd\n",
        "        self.kdtree=KDTree(self.all_bd)\n",
        "        self.k=k\n",
        "        #print(\"Archive constructor. size = %d\"%(len(self.all_bd)))\n",
        "\n",
        "    def update(self,new_bd):\n",
        "        oldsize=len(self.all_bd)\n",
        "        self.all_bd=self.all_bd + new_bd\n",
        "        self.kdtree=KDTree(self.all_bd)\n",
        "        #print(\"Archive updated, old size = %d, new size = %d\"%(oldsize,len(self.all_bd)))\n",
        "\n",
        "    def get_nov(self,bd, population=[]):\n",
        "\n",
        "        # A compléter pour calculer la nouveauté\n",
        "        # C'est la distance moyenne au self.k plus proches voisins parmi la population\n",
        "        # et l'archive, représentée ici par un kdtree (cf https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.html)\n",
        "        #<ANSWER>\n",
        "\n",
        "        dist_pop=[]\n",
        "        for i in population:\n",
        "            dist_pop.append(np.linalg.norm(np.array(bd)-np.array(ind.bd)))\n",
        "        archive,i=self.kdtree.query(np.array(bd),self.k)\n",
        "        dist=dist_pop+list(archive)\n",
        "        dist.sort()\n",
        "        sum=0\n",
        "        for i in range(k):\n",
        "            sum+=dist[i+1]\n",
        "        sum = sum/self.k\n",
        "        return sum\n",
        "        #</ANSWER>\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.all_bd)\n",
        "\n",
        "def updateNovelty(population, offspring, archive, k=15, add_strategy=\"random\", _lambda=6, verbose=False):\n",
        "   \"\"\"Update the novelty criterion (including archive update)\n",
        "\n",
        "   Implementation of novelty search following (Gomes, J., Mariano, P., & Christensen, A. L. (2015, July). Devising effective novelty search algorithms: A comprehensive empirical study. In Proceedings of GECCO 2015 (pp. 943-950). ACM.).\n",
        "   :param population: is the set of indiv for which novelty needs to be computed\n",
        "   :param offspring: is the set of new individuals that need to be taken into account to update the archive\n",
        "   (may be the same as population, but it may also be different as population may contain the set of parents)\n",
        "   :param k: is the number of nearest neighbors taken into account\n",
        "   :param add_strategy: is either \"random\" (a random set of indiv is added to the archive) or \"novel\" (only the most novel individuals are added to the archive).\n",
        "   :param _lambda: is the number of individuals added to the archive for each generation\n",
        "   The default values correspond to the one giving the better results in the above mentionned paper.\n",
        "\n",
        "   The function returns the new archive\n",
        "   \"\"\"\n",
        "\n",
        "   # Novelty scores updates\n",
        "   if (archive) and (archive.size()>=k):\n",
        "       if (verbose):\n",
        "           print(\"Update Novelty. Archive size=%d\"%(archive.size()))\n",
        "       for ind in population:\n",
        "           ind.novelty=archive.get_nov(ind.bd, population)\n",
        "   else:\n",
        "       if (verbose):\n",
        "           print(\"Update Novelty. Initial step...\")\n",
        "       for ind in population:\n",
        "           ind.novelty=0.\n",
        "\n",
        "   if (verbose):\n",
        "       print(\"Fitness (novelty): \",end=\"\")\n",
        "       for ind in population:\n",
        "           print(\"%.2f, \"%(ind.novelty),end=\"\")\n",
        "       print(\"\")\n",
        "   if (len(offspring)<_lambda):\n",
        "       print(\"ERROR: updateNovelty, lambda(%d)<offspring size (%d)\"%(_lambda, len(offspring)))\n",
        "       return None\n",
        "\n",
        "   lbd=[]\n",
        "   # Update of the archive\n",
        "   if(add_strategy==\"random\"):\n",
        "       l=list(range(len(offspring)))\n",
        "       random.shuffle(l)\n",
        "       if (verbose):\n",
        "           print(\"Random archive update. Adding offspring: \"+str(l[:_lambda]))\n",
        "       lbd=[offspring[l[i]].bd for i in range(_lambda)]\n",
        "   elif(add_strategy==\"novel\"):\n",
        "       soff=sorted(offspring,lambda x:x.novelty)\n",
        "       ilast=len(offspring)-_lambda\n",
        "       lbd=[soff[i].bd for i in range(ilast,len(soff))]\n",
        "       if (verbose):\n",
        "           print(\"Novel archive update. Adding offspring: \")\n",
        "           for offs in soff[iLast:len(soff)]:\n",
        "               print(\"    nov=\"+str(offs.novelty)+\" fit=\"+str(offs.fitness.values)+\" bd=\"+str(offs.bd))\n",
        "   else:\n",
        "       print(\"ERROR: updateNovelty: unknown add strategy(%s), valid alternatives are \\\"random\\\" and \\\"novel\\\"\"%(add_strategy))\n",
        "       return None\n",
        "\n",
        "   if(archive==None):\n",
        "       archive=NovArchive(lbd,k)\n",
        "   else:\n",
        "       archive.update(lbd)\n",
        "\n",
        "   return archive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GdY-2rQ8dEsH",
        "outputId": "9846f151-772e-4a77-810b-2a43ffe0e0c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gym_fastsim_maze.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile gym_fastsim_maze.py\n",
        "\n",
        "# Cette cellule contient le code complet de l'expérience de navigation dans le maze.\n",
        "# Complétez les trous dans les balises <ANSWER></ANSWER>\n",
        "\n",
        "\n",
        "import gym, gym_fastsim\n",
        "\n",
        "from deap import *\n",
        "import numpy as np\n",
        "from nn import SimpleNeuralControllerNumpy\n",
        "from scipy.spatial import KDTree\n",
        "\n",
        "from deap import algorithms\n",
        "from deap import base\n",
        "from deap import benchmarks\n",
        "from deap import creator\n",
        "from deap import tools\n",
        "import argparse\n",
        "\n",
        "import array\n",
        "import random\n",
        "import operator\n",
        "import math\n",
        "\n",
        "from plot import *\n",
        "\n",
        "from scoop import futures\n",
        "\n",
        "from novelty_search import *\n",
        "\n",
        "weights=(-1.0,1.0)\n",
        "\n",
        "if (hasattr(creator, \"MyFitness\")):\n",
        "    # Deleting any previous definition (to avoid warning message)\n",
        "    print(\"Main: destroying myfitness\")\n",
        "    del creator.MyFitness\n",
        "creator.create(\"MyFitness\", base.Fitness, weights=(weights))\n",
        "\n",
        "if (hasattr(creator, \"Individual\")):\n",
        "    # Deleting any previous definition (to avoid warning message)\n",
        "    del creator.Individual\n",
        "creator.create(\"Individual\", list, fitness=creator.MyFitness)\n",
        "\n",
        "# Evaluation d'un réseau de neurones en utilisant gym\n",
        "def eval_nn(genotype, nbstep=2000, render=False, name=\"\"):\n",
        "    \"\"\"Evaluation d'une politique parametrée par le génotype\n",
        "\n",
        "    Evaluation d'une politique parametrée par le génotype\n",
        "    :param genotype: le paramètre de politique à évaluer\n",
        "    :param nbstep: le nombre maximum de pas de temps\n",
        "    :param render: affichage/sauvegarde de la trajectoire du robot\n",
        "    :param name: nom à donner au fichier de log\n",
        "    \"\"\"\n",
        "\n",
        "    # Cette fonction fait l'évaluation d'un genotype utilisé pour\n",
        "    # paraméter un réseau de neurones de structure fixe.\n",
        "    # En vue de l'expérience avec novelty_search, elle renvoie:\n",
        "    # - la fitness: distance à la sortie à minimiser (qui peut se récupérer dans la 4eme\n",
        "    #valeur de retour de la méthode step, qui est un dictionnaire dans lequel la clé \"dist_obj\"\n",
        "    #donne accès à l'opposé de la distance à la sortie)\n",
        "    # - le descripteur comportemental, qui est la position finale qui est accessible depuis\n",
        "    #le même dictionnaire (clé \"robot_pos\", dont il ne faut garder que les 2 premières composantes)\n",
        "\n",
        "    nn=SimpleNeuralControllerNumpy(5,2,2,10)\n",
        "    nn.set_parameters(genotype)\n",
        "    observation = env.reset()\n",
        "    old_pos=None\n",
        "    total_dist=0\n",
        "    if (render):\n",
        "        f=open(\"traj\"+name+\".log\",\"w\")\n",
        "\n",
        "    for t in range(nbstep):\n",
        "        if render:\n",
        "            env.render()\n",
        "        action=nn.predict(observation)\n",
        "        observation, reward, done, info = env.step(action)\n",
        "        pos=info[\"robot_pos\"][:2]\n",
        "        if(render):\n",
        "            f.write(\" \".join(map(str,pos))+\"\\n\")\n",
        "        if (old_pos is not None):\n",
        "            d=math.sqrt((pos[0]-old_pos[0])**2+(pos[1]-old_pos[1])**2)\n",
        "            total_dist+=d\n",
        "        old_pos=list(pos)\n",
        "        if(done):\n",
        "            break\n",
        "    if (render):\n",
        "        f.close()\n",
        "    dist_obj=info[\"dist_obj\"] # c'est l'opposé de la distance à la sortie\n",
        "    #print(\"End of eval, total_dist=%f\"%(total_dist))\n",
        "    # Remarque: les positions et distances sont arrondis à 2 décimales pour éviter le surapprentissage et le maintien dans le front de pareto de solutions ne différant que\n",
        "    # de décimales plus éloignées (variante FIT+NS)\n",
        "    rpos=[round(x,2) for x in pos]\n",
        "    return round(dist_obj,2), rpos\n",
        "\n",
        "\n",
        "def nsga2_NS(n=100, nbgen=200, IND_SIZE=10, variant=\"FIT\", MIN_V=-30, MAX_V=30, CXPB=0.6, MUTPB=0.3, verbose=False):\n",
        "\n",
        "    # votre code contiendra donc des tests comme suit pour gérer la différence entre ces variantes:\n",
        "    if (hasattr(creator, \"MyFitness\")):\n",
        "        # Deleting any previous definition (to avoid warning message)\n",
        "        print(\"nsga2_NS: destroying myfitness\")\n",
        "        del creator.MyFitness\n",
        "\n",
        "    # Attention: le signe du poids associé à la fitness doit être adapté aux valeurs renvoyées par eval_nn (négatif si valeur à minimiser et positif si à maximiser)\n",
        "    if (variant==\"FIT+NS\"):\n",
        "        #print(\"Creator: FIT+NS\")\n",
        "        creator.create(\"MyFitness\", base.Fitness, weights=(-1.0,1.0))\n",
        "    elif (variant==\"FIT\"):\n",
        "        #print(\"Creator: FIT\")\n",
        "        creator.create(\"MyFitness\", base.Fitness, weights=(-1.0,))\n",
        "    elif (variant==\"NS\"):\n",
        "        #print(\"Creator: NS\")\n",
        "        creator.create(\"MyFitness\", base.Fitness, weights=(1.0,))\n",
        "    else:\n",
        "        print(\"Variante inconnue: \"+variant)\n",
        "\n",
        "    if (hasattr(creator, \"Individual\")):\n",
        "        # Deleting any previous definition (to avoid warning message)\n",
        "        del creator.Individual\n",
        "    creator.create(\"Individual\", list, fitness=creator.MyFitness)\n",
        "\n",
        "\n",
        "    toolbox = base.Toolbox()\n",
        "    toolbox.register(\"attribute\", random.uniform, MIN_V, MAX_V)\n",
        "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual,\n",
        "            toolbox.attribute, n=IND_SIZE)\n",
        "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "    toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, eta=15, low=MIN_V, up=MAX_V)\n",
        "    toolbox.register(\"mutate\", tools.mutPolynomialBounded, eta=15, low=MIN_V, up=MAX_V, indpb=1/IND_SIZE)\n",
        "    toolbox.register(\"select\", tools.selNSGA2, k=n)\n",
        "    toolbox.register(\"select_dcd\", tools.selTournamentDCD, k=n)\n",
        "    toolbox.register(\"evaluate\", eval_nn, render=True)\n",
        "\n",
        "    toolbox.register(\"map\",futures.map)\n",
        "\n",
        "\n",
        "    population = toolbox.population(n=n)\n",
        "    paretofront = tools.ParetoFront()\n",
        "\n",
        "    # Permet de sauvegarder les descripteurs comportementaux de tous les individus rencontrés.\n",
        "    # vous pouvez tracer les descripteurs générés depuis une cellule de jupyter avec la commande:\n",
        "    # plot_points_file(\"bd.log\")\n",
        "    fbd=open(\"bd.log\",\"w\")\n",
        "\n",
        "    # Evaluate the individuals with an invalid fitness\n",
        "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
        "    fitnesses_bds = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "    for ind, (fit, bd) in zip(invalid_ind, fitnesses_bds):\n",
        "        #print(\"Fit: \"+str(fit))\n",
        "        #print(\"BD: \"+str(bd))\n",
        "        # Complétez pour positionner fitness.values selon la variante choisie\n",
        "        #<ANSWER>\n",
        "        if (variant==\"FIT+NS\"):\n",
        "          #print(\"Creator: FIT+NS\")\n",
        "          ind.fitness.values = (fit, 0)\n",
        "        elif (variant==\"FIT\"):\n",
        "          #print(\"Creator: FIT\")\n",
        "          ind.fitness.values = (fit,)\n",
        "        elif (variant==\"NS\"):\n",
        "          #print(\"Creator: NS\")\n",
        "          ind.fitness.values = (0,)\n",
        "        else:\n",
        "          print(\"Variante inconnue: \"+variant)\n",
        "        #</ANSWER>\n",
        "\n",
        "        fbd.write(\" \".join(map(str,bd))+\"\\n\")\n",
        "        fbd.flush()\n",
        "        ind.fit=fit\n",
        "        ind.bd=bd\n",
        "\n",
        "    if paretofront is not None:\n",
        "        paretofront.update(population)\n",
        "\n",
        "    #print(\"Pareto Front: \"+str(paretofront))\n",
        "\n",
        "    k=15\n",
        "    add_strategy=\"random\"\n",
        "    lambdaNov=6\n",
        "\n",
        "    # Crée l'archive et mets à jour les champs ind.novelty de chaque individu\n",
        "    archive=updateNovelty(population,population,None,k,add_strategy,lambdaNov)\n",
        "\n",
        "    # Selon la variante, complétez ind.fitness.values pour ajouter la valeur de ind.novelty qui vient d'être calculée\n",
        "    #<ANSWER>\n",
        "    for ind in population:\n",
        "        if (variant==\"FIT+NS\"):\n",
        "            #print(\"Creator: FIT+NS\")\n",
        "            fit, _ = ind.fitness.values\n",
        "            ind.fitness.values = (fit, ind.novelty)\n",
        "        #elif (variant==\"FIT\"):\n",
        "            #print(\"Creator: FIT\")\n",
        "        elif (variant==\"NS\"):\n",
        "            #print(\"Creator: NS\")\n",
        "            ind.fitness.values = (ind.novelty,)\n",
        "        else:\n",
        "            print(\"Variante inconnue: \"+variant)\n",
        "\n",
        "    #</ANSWER>\n",
        "\n",
        "\n",
        "    indexmin, valuemin = max(enumerate([i.fit for i in population]), key=operator.itemgetter(1))\n",
        "\n",
        "    # Pour le calcul des crowdingDistances si utilisation de selTournamentDCD\n",
        "    population[:] = toolbox.select(population)\n",
        "\n",
        "    pq = population\n",
        "    # Begin the generational process\n",
        "    for gen in range(1, nbgen + 1):\n",
        "        if (gen%10==0):\n",
        "            print(\"+\",end=\"\", flush=True)\n",
        "        else:\n",
        "            print(\".\",end=\"\", flush=True)\n",
        "\n",
        "        # Complétez avec un NSGA-2 en prenant soin de mettre à jour les calculs de nouveauté et d'ajouter les\n",
        "        # nouveautés à la fitness des individus.\n",
        "\n",
        "        # ATTENTION: dans la mise à jour de la nouveauté (updateNovelty), vérifiez bien la signification du premier et du 2eme argument.\n",
        "        # l'appel fait plus haut doit être adapté: la nouveauté de TOUS les individus doit être recalculée (parents+enfants)\n",
        "        # et les individus susceptibles d'être ajoutés à l'archive ne doivent être pris que parmi les enfants.\n",
        "\n",
        "        #<ANSWER>\n",
        "        tools.selNSGA2(population, len(population))\n",
        "        pop = toolbox.select_dcd(population)\n",
        "\n",
        "        offspring=list(map(toolbox.clone, pop))\n",
        "        #Mutation et apparimment\n",
        "        offspring=algorithms.varAnd(offspring, toolbox, CXPB, MUTPB)\n",
        "\n",
        "        #La rajouter à la population sélectionnée\n",
        "        population=offspring\n",
        "\n",
        "        # Evaluate the individuals with an invalid fitness\n",
        "        invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
        "        fitnesses_bds = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "        for ind, (fit, bd) in zip(invalid_ind, fitnesses_bds):\n",
        "            #print(\"Fit: \"+str(fit))\n",
        "            #print(\"BD: \"+str(bd))\n",
        "            # Complétez pour positionner fitness.values selon la variante choisie\n",
        "            if (variant==\"FIT+NS\"):\n",
        "                ind.fitness.values = (fit, 0)\n",
        "            elif (variant==\"FIT\"):\n",
        "                ind.fitness.values = (fit,)\n",
        "            elif (variant==\"NS\"):\n",
        "                ind.fitness.values = (0,)\n",
        "            ind.fit=fit\n",
        "            ind.bd=bd\n",
        "\n",
        "        # Update the hall of fame with the generated individuals\n",
        "        if paretofront is not None:\n",
        "            paretofront.update(population)\n",
        "\n",
        "        # Crée l'archive et mets à jour les champs ind.novelty de chaque individu\n",
        "        archive=updateNovelty(population,population,None,k,add_strategy,lambdaNov)\n",
        "\n",
        "        # Selon la variante, complétez ind.fitness.values pour ajouter la valeur de ind.novelty qui vient d'être calculée\n",
        "        for ind in population:\n",
        "            if (variant==\"FIT+NS\"):\n",
        "                fit, _ = ind.fitness.values\n",
        "                ind.fitness.values = (fit, ind.novelty)\n",
        "            elif (variant==\"NS\"):\n",
        "                ind.fitness.values = (ind.novelty,)\n",
        "\n",
        "\n",
        "        # used to track the max value (useful in particular if using only novelty)\n",
        "        indexmin, newvaluemin = min(enumerate([i.fit for i in pq]), key=operator.itemgetter(1))\n",
        "        if (newvaluemin<valuemin):\n",
        "            valuemin=newvaluemin\n",
        "            print(\"Gen \"+str(gen)+\", new min ! min fit=\"+str(valuemin)+\" index=\"+str(indexmin))\n",
        "            eval_nn(pq[indexmin],True,\"gen%04d\"%(gen))\n",
        "    fbd.close()\n",
        "    return population, None, paretofront\n",
        "\n",
        "\n",
        "env = gym.make('FastsimSimpleNavigation-v0')\n",
        "\n",
        "if (__name__ == \"__main__\"):\n",
        "\n",
        "    parser = argparse.ArgumentParser(description='Launch maze navigation experiment.')\n",
        "    parser.add_argument('--nbgen', type=int, default=200,\n",
        "                        help='number of generations')\n",
        "    parser.add_argument('--popsize', type=int, default=100,\n",
        "                        help='population size')\n",
        "    parser.add_argument('--res_dir', type=str, default=\"res\",\n",
        "                        help='basename of the directory in which to put the results')\n",
        "    parser.add_argument('--variant', type=str, default=\"FIT\", choices=['FIT', 'NS', 'FIT+NS'],\n",
        "                        help='variant to consider')\n",
        "\n",
        "    # Il vous est recommandé de gérer les différentes variantes avec cette variable. Les 3 valeurs possibles seront:\n",
        "    # \"FIT+NS\": expérience multiobjectif avec la fitness et la nouveauté (NSGA-2)\n",
        "    # \"NS\": nouveauté seule\n",
        "    # \"FIT\": fitness seule\n",
        "    # pour les variantes avec un seul objectif, il vous est cependant recommandé d'utiliser NSGA-2 car cela limitera la différence entre les variantes et cela\n",
        "    # vous fera gagner du temps pour la suite.\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    print(\"Number of generations: \"+str(args.nbgen))\n",
        "    nbgen=args.nbgen\n",
        "    print(\"Population size: \"+str(args.popsize))\n",
        "    popsize=args.popsize\n",
        "    print(\"Variant: \"+args.variant)\n",
        "    variant=args.variant\n",
        "\n",
        "    nn=SimpleNeuralControllerNumpy(5,2,2,10)\n",
        "    IND_SIZE=len(nn.get_parameters())\n",
        "\n",
        "    pop, logbook, paretofront= nsga2_NS(n=popsize, variant=variant, nbgen=nbgen, IND_SIZE=IND_SIZE)\n",
        "    #plot_pareto_front(paretofront, \"Final pareto front\")\n",
        "    for i,p in enumerate(paretofront):\n",
        "        print(\"Visualizing indiv \"+str(i)+\", fit=\"+str(p.fitness.values))\n",
        "        eval_nn(p,True)\n",
        "\n",
        "    env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJkpX1X4BEGQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
